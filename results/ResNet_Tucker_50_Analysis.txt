[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
[MAdd]: Sequential is not supported!
[Flops]: Sequential is not supported!
[Memory]: Sequential is not supported!
               module name  input shape output shape     params memory(MB)           MAdd          Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)
0                    conv1    3  32  32   64  32  32     1728.0       0.25    3,473,408.0    1,769,472.0     19200.0     262144.0       3.99%    281344.0
1                      bn1   64  32  32   64  32  32      128.0       0.25      262,144.0      131,072.0    262656.0     262144.0       1.44%    524800.0
2           layer1.0.conv1   64  32  32   64  32  32    36864.0       0.25   75,431,936.0   37,748,736.0    409600.0     262144.0       9.97%    671744.0
3             layer1.0.bn1   64  32  32   64  32  32      128.0       0.25      262,144.0      131,072.0    262656.0     262144.0       1.24%    524800.0
4         layer1.0.conv2.0   64  32  32   22  32  32     1408.0       0.09    2,861,056.0    1,441,792.0    267776.0      90112.0       4.79%    357888.0
5         layer1.0.conv2.1   22  32  32   22  32  32     4356.0       0.09    8,898,560.0    4,460,544.0    107536.0      90112.0       3.65%    197648.0
6         layer1.0.conv2.2   22  32  32   64  32  32     1472.0       0.25    2,883,584.0    1,507,328.0     96000.0     262144.0       2.82%    358144.0
7             layer1.0.bn2   64  32  32   64  32  32      128.0       0.25      262,144.0      131,072.0    262656.0     262144.0       0.40%    524800.0
8        layer1.0.shortcut   64  32  32   64  32  32        0.0       0.25            0.0            0.0         0.0          0.0       0.54%         0.0
9           layer1.1.conv1   64  32  32   64  32  32    36864.0       0.25   75,431,936.0   37,748,736.0    409600.0     262144.0       1.87%    671744.0
10            layer1.1.bn1   64  32  32   64  32  32      128.0       0.25      262,144.0      131,072.0    262656.0     262144.0       0.55%    524800.0
11        layer1.1.conv2.0   64  32  32   16  32  32     1024.0       0.06    2,080,768.0    1,048,576.0    266240.0      65536.0       4.10%    331776.0
12        layer1.1.conv2.1   16  32  32   20  32  32     2880.0       0.08    5,877,760.0    2,949,120.0     77056.0      81920.0       1.16%    158976.0
13        layer1.1.conv2.2   20  32  32   64  32  32     1344.0       0.25    2,621,440.0    1,376,256.0     87296.0     262144.0       0.89%    349440.0
14            layer1.1.bn2   64  32  32   64  32  32      128.0       0.25      262,144.0      131,072.0    262656.0     262144.0       0.39%    524800.0
15       layer1.1.shortcut   64  32  32   64  32  32        0.0       0.25            0.0            0.0         0.0          0.0       0.02%         0.0
16          layer2.0.conv1   64  32  32  128  16  16    73728.0       0.12   37,715,968.0   18,874,368.0    557056.0     131072.0       5.46%    688128.0
17            layer2.0.bn1  128  16  16  128  16  16      256.0       0.12      131,072.0       65,536.0    132096.0     131072.0       0.35%    263168.0
18        layer2.0.conv2.0  128  16  16   43  16  16     5504.0       0.04    2,807,040.0    1,409,024.0    153088.0      44032.0       4.22%    197120.0
19        layer2.0.conv2.1   43  16  16   78  16  16    30186.0       0.08   15,435,264.0    7,727,616.0    164776.0      79872.0       3.00%    244648.0
20        layer2.0.conv2.2   78  16  16  128  16  16    10112.0       0.12    5,111,808.0    2,588,672.0    120320.0     131072.0       1.18%    251392.0
21            layer2.0.bn2  128  16  16  128  16  16      256.0       0.12      131,072.0       65,536.0    132096.0     131072.0       0.38%    263168.0
22     layer2.0.shortcut.0   64  32  32  128  16  16     8192.0       0.12    4,161,536.0    2,097,152.0    294912.0     131072.0       4.32%    425984.0
23     layer2.0.shortcut.1  128  16  16  128  16  16      256.0       0.12      131,072.0       65,536.0    132096.0     131072.0       0.36%    263168.0
24          layer2.1.conv1  128  16  16  128  16  16   147456.0       0.12   75,464,704.0   37,748,736.0    720896.0     131072.0       4.92%    851968.0
25            layer2.1.bn1  128  16  16  128  16  16      256.0       0.12      131,072.0       65,536.0    132096.0     131072.0       0.33%    263168.0
26        layer2.1.conv2.0  128  16  16   14  16  16     1792.0       0.01      913,920.0      458,752.0    138240.0      14336.0       3.52%    152576.0
27        layer2.1.conv2.1   14  16  16   30  16  16     3780.0       0.03    1,927,680.0      967,680.0     29456.0      30720.0       0.92%     60176.0
28        layer2.1.conv2.2   30  16  16  128  16  16     3968.0       0.12    1,966,080.0    1,015,808.0     46592.0     131072.0       0.75%    177664.0
29            layer2.1.bn2  128  16  16  128  16  16      256.0       0.12      131,072.0       65,536.0    132096.0     131072.0       0.38%    263168.0
30       layer2.1.shortcut  128  16  16  128  16  16        0.0       0.12            0.0            0.0         0.0          0.0       0.02%         0.0
31          layer3.0.conv1  128  16  16  256   8   8   294912.0       0.06   37,732,352.0   18,874,368.0   1310720.0      65536.0       4.65%   1376256.0
32            layer3.0.bn1  256   8   8  256   8   8      512.0       0.06       65,536.0       32,768.0     67584.0      65536.0       0.36%    133120.0
33        layer3.0.conv2.0  256   8   8  110   8   8    28160.0       0.03    3,597,440.0    1,802,240.0    178176.0      28160.0       1.54%    206336.0
34        layer3.0.conv2.1  110   8   8  119   8   8   117810.0       0.03   15,072,064.0    7,539,840.0    499400.0      30464.0       2.19%    529864.0
35        layer3.0.conv2.2  119   8   8  256   8   8    30720.0       0.06    3,899,392.0    1,966,080.0    153344.0      65536.0       0.55%    218880.0
36            layer3.0.bn2  256   8   8  256   8   8      512.0       0.06       65,536.0       32,768.0     67584.0      65536.0       0.38%    133120.0
37     layer3.0.shortcut.0  128  16  16  256   8   8    32768.0       0.06    4,177,920.0    2,097,152.0    262144.0      65536.0       3.30%    327680.0
38     layer3.0.shortcut.1  256   8   8  256   8   8      512.0       0.06       65,536.0       32,768.0     67584.0      65536.0       0.36%    133120.0
39          layer3.1.conv1  256   8   8  256   8   8   589824.0       0.06   75,481,088.0   37,748,736.0   2424832.0      65536.0       2.20%   2490368.0
40            layer3.1.bn1  256   8   8  256   8   8      512.0       0.06       65,536.0       32,768.0     67584.0      65536.0       0.37%    133120.0
41        layer3.1.conv2.0  256   8   8   41   8   8    10496.0       0.01    1,340,864.0      671,744.0    107520.0      10496.0       1.11%    118016.0
42        layer3.1.conv2.1   41   8   8   48   8   8    17712.0       0.01    2,264,064.0    1,133,568.0     81344.0      12288.0       1.76%     93632.0
43        layer3.1.conv2.2   48   8   8  256   8   8    12544.0       0.06    1,572,864.0      802,816.0     62464.0      65536.0       0.52%    128000.0
44            layer3.1.bn2  256   8   8  256   8   8      512.0       0.06       65,536.0       32,768.0     67584.0      65536.0       0.35%    133120.0
45       layer3.1.shortcut  256   8   8  256   8   8        0.0       0.06            0.0            0.0         0.0          0.0       0.02%         0.0
46          layer4.0.conv1  256   8   8  512   4   4  1179648.0       0.03   37,740,544.0   18,874,368.0   4784128.0      32768.0       1.30%   4816896.0
47            layer4.0.bn1  512   4   4  512   4   4     1024.0       0.03       32,768.0       16,384.0     36864.0      32768.0       0.39%     69632.0
48        layer4.0.conv2.0  512   4   4  119   4   4    60928.0       0.01    1,947,792.0      974,848.0    276480.0       7616.0       1.82%    284096.0
49        layer4.0.conv2.1  119   4   4   79   4   4    84609.0       0.00    2,706,224.0    1,353,744.0    346052.0       5056.0       1.82%    351108.0
50        layer4.0.conv2.2   79   4   4  512   4   4    40960.0       0.03    1,294,336.0      655,360.0    168896.0      32768.0       0.47%    201664.0
51            layer4.0.bn2  512   4   4  512   4   4     1024.0       0.03       32,768.0       16,384.0     36864.0      32768.0       0.40%     69632.0
52     layer4.0.shortcut.0  256   8   8  512   4   4   131072.0       0.03    4,186,112.0    2,097,152.0    589824.0      32768.0       0.63%    622592.0
53     layer4.0.shortcut.1  512   4   4  512   4   4     1024.0       0.03       32,768.0       16,384.0     36864.0      32768.0       0.41%     69632.0
54          layer4.1.conv1  512   4   4  512   4   4  2359296.0       0.03   75,489,280.0   37,748,736.0   9469952.0      32768.0       1.96%   9502720.0
55            layer4.1.bn1  512   4   4  512   4   4     1024.0       0.03       32,768.0       16,384.0     36864.0      32768.0       0.40%     69632.0
56        layer4.1.conv2.0  512   4   4    8   4   4     4096.0       0.00      130,944.0       65,536.0     49152.0        512.0       0.80%     49664.0
57        layer4.1.conv2.1    8   4   4   12   4   4      864.0       0.00       27,456.0       13,824.0      3968.0        768.0       0.60%      4736.0
58        layer4.1.conv2.2   12   4   4  512   4   4     6656.0       0.03      196,608.0      106,496.0     27392.0      32768.0       0.42%     60160.0
59            layer4.1.bn2  512   4   4  512   4   4     1024.0       0.03       32,768.0       16,384.0     36864.0      32768.0       0.39%     69632.0
60       layer4.1.shortcut  512   4   4  512   4   4        0.0       0.03            0.0            0.0         0.0          0.0       0.02%         0.0
61                  linear          512           10     5130.0       0.00       10,230.0        5,120.0     22568.0         40.0       0.60%     22608.0
total                                                 5390463.0       5.97  596,389,622.0  298,698,896.0     22568.0         40.0     100.00%  32787236.0
=========================================================================================================================================================
Total params: 5,390,463
---------------------------------------------------------------------------------------------------------------------------------------------------------
Total memory: 5.97MB
Total MAdd: 596.39MMAdd
Total Flops: 298.7MFlops
Total MemR+W: 31.27MB

CPU prediction time 0.03204132031790818 79
inference time: 0:00:03.738330
Accuracy of the network on the test images: 80.21 %